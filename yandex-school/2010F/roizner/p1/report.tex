\documentclass[a4paper, 12pt, onepage]{article}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{fullpage}
\usepackage{indentfirst}
\usepackage{graphicx}
\usepackage{cmap}
\usepackage{amsmath}
\usepackage{amssymb}
%\usepackage{pdfpages}
%\usepackage{tikz}
\usepackage{framed}

\usepackage[pdftex, unicode, pdfstartview=FitH, colorlinks, linkcolor=black, citecolor=blue, urlcolor=blue]{hyperref}
\usepackage{url}
\def\UrlFont{\rmfamily}

\usepackage{setspace}
\onehalfspacing

\usepackage{cyrtimes}
\renewcommand\ttdefault{cmtt}

\frenchspacing
\sloppy
\selectlanguage{russian}

\begin{document}

\author{Красильников Иван}
\title{Problem set 1}
\maketitle

\subsection*{Задача 1}
Да. $a(x) = \mbox{sign}\left(-3 + [x_1 > 0] + [x_1 < 1] + [x_2 > 0] + [x_2 < 1]\right)$.

\subsection*{Задача 2}
Нет. Нельзя, например, описать $\{ (x, y)\,|\,xy > 0 \}$ (т.е. решить XOR), что можно показать
невозможностью отделить точки $(1, 1), (-1, -1)$ от $(-1, 1), (1, -1)$ решающими правилами
вида $\mbox{sign}(f(x) + g(y))$:

$$
\begin{cases}
f(1) + g(1) > 0, \\
f(-1) + g(-1) > 0, \\
f(-1) + g(1) < 0, \\
f(1) + g(-1) < 0, \\
\end{cases}
\implies
\begin{cases}
f(1) > -g(1) \\
f(-1) > -g(-1) \\
f(-1) < -g(1), \\
f(1) < -g(-1), \\
\end{cases}
\implies
$$
$f(1) > -g(1) > f(-1) > -g(-1) > f(1)$, что неверно.



\newpage
\subsection*{Задача 4}

Веса пересчитываются по формуле:

$$ w_{t+1}(i) = 
\begin{cases}
  \frac{w_{t}(i)}{2 \epsilon_t}, & y_i = h_t(x_i), \\
  \frac{w_{t}(i)}{2 (1 - \epsilon_t)}, & y_i \ne h_t(x_i). \\
\end{cases}
$$
$$
\epsilon_t = \sum_{i=1}^n w_t(i) [y_i \ne h_t(x_i)]
$$

Значение функционала взвешенной ошибки для базового алгоритма $t$-го шага, взятое с весами $w_{t+1}$, равно:

$$
\sum_{i=1}^n w_{t+1}(i) [y_i \ne h_t(x_i)] =
\sum_{i=1}^n \frac{  w_{t}(i) [y_i \ne h_t(x_i)]}{2(1 - \epsilon_t)} =
\frac{ \epsilon_t }{2(1 - \epsilon_t)},
$$
где $\epsilon_t$ -- значение этого же функционала при весах $w_t$.
Таким образом, значение функционала уменьшается, если $\epsilon_t > 0.5$.

\newpage
\subsection*{Задача 5}

Пусть задана выборка $\{ (x_i, y_i) \}_{i=1}^n$, $x_i \in \mathbb{R}^m$, $y_i \in \mathbb{R}$,
и требуется найти $f(x)$, минимизирующую сумму квадратов ошибок:
$ \sum_{i=1}^n (f(x_i) - y_i)^2$.

На первом шаге положим $f_0(x) = \frac1n \sum_{i=1}^n y_i$ --- наилучшее константное приближение.

Далее, следуя общей концепции бустинга, на $t$-м шаге будем искать $f_t(x)$
в виде $f_t(x) = f_{t-1}(x) + h(x)$, где $h(x)$ -- функция, возвращаемая базовым
алгоритмом обучения, критерий выбора которой -- минимизация квадратичной ошибки функции $f_t(x)$:

$$ \sum_{i=1}^n (y_i - f_t(x_i))^2 \to \min_h $$
$$ \sum_{i=1}^n ([y_i - f_{t-1}(x_i)] - h(x_i))^2 \to \min_h $$

Таким образом, для выбора $h(x)$ необходимо решить задачу регрессии на
выборке $ \{ (x_i, y_i - f_{t-1}(x_i)) \}_{i=1}^n$. Это уже задача для базового алгоритма регрессии.

Алгоритм построен. \hfill $\blacksquare$

\bigskip
\begin{framed}
Псевдокод:
\begin{enumerate}
  \item $f_0(x) := \frac1n \sum_{i=1}^n y_i$.
  \item Для $t = 1, 2, \ldots, T$:
    \begin{enumerate}
      \item Построить функцию $h(x)$ при помощи базового алгоритма для решения задачи регрессии:
        $$ h(x) = \underset{h}{\operatorname{arg\,max}} \sum_{i=1}^n (h(x_i) - r_i)^2,$$
	где $r_i = y_i - f_{t-1}(x_i)$.
      \item $f_t(x) := f_{t-1}(x) + h(x)$:
    \end{enumerate}
  \item Вывести $f_T(x)$.
\end{enumerate}
\end{framed}



\end{document}
